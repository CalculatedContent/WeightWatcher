{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Conv2D SVD method from Google Brain\n",
    "\n",
    "https://www.mis.mpg.de/fileadmin/pdf/slides_lroa2019_4125.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "(384, 192, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "layer = 8\n",
    "for im, m in enumerate(alexnet.modules()):\n",
    "    if im ==8:\n",
    "        print(im,m)\n",
    "        T = np.array(m.weight.data.clone().cpu()) \n",
    "        print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import powerlaw\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "class WW:\n",
    "\n",
    "    def __init__(self, model=None, log=True, logger=None):\n",
    "        self.model = self.load_model(model)\n",
    "#        self.alphas = {}\n",
    "        self.results = {}\n",
    "        self.summary = {}\n",
    "        self.logger_set(log=log, logger=logger)\n",
    "\n",
    "        self.info(self.banner())\n",
    "\n",
    "\n",
    "    def logger_set(self, log=True, logger=None):\n",
    "        self.log = log\n",
    "        self.logger = None\n",
    "        if logger:\n",
    "            self.logger = logger\n",
    "        else:\n",
    "            self.logger = logging.getLogger(__name__)\n",
    "            if not self.logger.handlers: # do not register handlers more than once\n",
    "                if log:\n",
    "                    #logging.basicConfig(level=logging.DEBUG)\n",
    "                    log_level = logging.INFO\n",
    "                    self.logger.setLevel(log_level)\n",
    "                    console_handler = logging.StreamHandler()\n",
    "                    console_handler.setLevel(log_level)\n",
    "                    formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\")\n",
    "                    console_handler.setFormatter(formatter)\n",
    "                    self.logger.addHandler(console_handler)\n",
    "                else:\n",
    "                    self.logger.addHandler(logging.NullHandler())\n",
    "\n",
    "\n",
    "    def header(self):\n",
    "        \"\"\"WeightWatcher v0.1.dev0 by Calculation Consulting\"\"\"\n",
    "#        from weightwatcher import __name__, __version__, __author__, __description__, __url__\n",
    "#        return \"{} v{} by {}\\n{}\\n{}\".format(__name__, __version__, __author__, __description__, __url__)\n",
    "        return \"\"\n",
    "\n",
    "    def banner(self):\n",
    "        versions  = \"\\npython      version {}\".format(sys.version)\n",
    "        versions += \"\\nnumpy       version {}\".format(np.__version__)\n",
    "        versions += \"\\ntensforflow version {}\".format(tf.__version__)\n",
    "        versions += \"\\nkeras       version {}\".format(keras.__version__)\n",
    "        return \"\\n{}{}\".format(self.header(), versions)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        done = bool(self.results)\n",
    "        txt  = \"\\nAnalysis done: {}\".format(done)\n",
    "        return \"{}{}\".format(self.header(), txt)\n",
    "\n",
    "\n",
    "    def debug(self, message):\n",
    "        if self.log:\n",
    "            self.logger.debug(message)\n",
    "\n",
    "\n",
    "    def info(self, message):\n",
    "        if self.log:\n",
    "            self.logger.info(message)\n",
    "\n",
    "\n",
    "    def warn(self, message):\n",
    "        if self.log:\n",
    "            self.logger.warning(message)\n",
    "\n",
    "\n",
    "    def error(self, message):\n",
    "        if self.log:\n",
    "            self.logger.error(message)\n",
    "\n",
    "            \n",
    "    def load_model(self, model):\n",
    "        \"\"\"Load a model from a file if necessary.\n",
    "        \"\"\"\n",
    "        res = model\n",
    "        if isinstance(model, str):\n",
    "            if os.path.isfile(model):\n",
    "                self.info(\"Loading model from file '{}'\".format(model))\n",
    "                res = load_model(model)\n",
    "            else:\n",
    "                self.error(\"Loading model from file '{}': file not found\".format(model))\n",
    "        return res\n",
    "\n",
    "\n",
    "    def model_is_valid(self, model=None):\n",
    "        model = model or self.model\n",
    "        if not model:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "    def get_conv2D_Wmats(self, Wtensor):\n",
    "        \"\"\"Extract W slices from a 4 index conv2D tensor of shape: (N,M,i,j) or (M,N,i,j).  \n",
    "        Return ij (N x M) matrices\n",
    "\n",
    "        \"\"\"\n",
    "        Wmats = []\n",
    "        s = Wtensor.shape\n",
    "        N, M, imax, jmax = s[0],s[1],s[2],s[3]\n",
    "        if N + M >= imax + jmax:\n",
    "            self.debug(\"Pytorch tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))\n",
    "\n",
    "            for i in range(imax):\n",
    "                for j in range(jmax):\n",
    "                    W = Wtensor[:,:,i,j]\n",
    "                    if N < M:\n",
    "                        W = W.T\n",
    "                    Wmats.append(W)\n",
    "        else:\n",
    "            N, M, imax, jmax = imax, jmax, N, M          \n",
    "            self.debug(\"Keras tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))\n",
    "\n",
    "            for i in range(imax):\n",
    "                for j in range(jmax):\n",
    "                    W = Wtensor[i,j,:,:]\n",
    "                    if N < M:\n",
    "                        W = W.T\n",
    "                    Wmats.append(W)\n",
    "\n",
    "        return Wmats\n",
    "\n",
    "    def norm_check(self, weight, N, M, receptive_field_size, \n",
    "                   lower = 0.5, upper = 1.5):\n",
    "\n",
    "        kappa = np.sqrt( 2 / ((N + M)*receptive_field_size) )\n",
    "        norm = np.linalg.norm(weight)\n",
    "\n",
    "\n",
    "        check1 = norm / np.sqrt(N*M)\n",
    "        check2 = norm / (kappa*np.sqrt(N*M))\n",
    "        if (check2 > lower) & (check2 < upper):   \n",
    "            #aka, if Glorot normalization\n",
    "            return weight / (kappa * np.sqrt(N))   \n",
    "        elif (check1 > lower) & (check1 < upper): \n",
    "            return weight / np.sqrt(N)      \n",
    "        else:\n",
    "            return weight\n",
    "\n",
    "\n",
    "    def analyze_weight_matrices(self, weights, layer_id, min_size=50, max_size=0,\n",
    "                        alphas=False,  spectralnorms=False, softranks=False,\n",
    "                        normalize=False,  mp_fit=False,\n",
    "                        conv2Dsvd=False,  plot=False):\n",
    "        \"\"\"Analyzes 1 or  weight matrices (assuming all the same shape)\"\"\"\n",
    "\n",
    "\n",
    "        # reset options to be consistent\n",
    "        if (conv2Dsvd or mp_fit):\n",
    "            alphas = True\n",
    "\n",
    "        if (alphas or spectralnorms or softranks):\n",
    "            spectralnorms = True\n",
    "            softranks = True\n",
    "\n",
    "        res = {}\n",
    "        count = len(weights)\n",
    "        if count == 0:\n",
    "            return res\n",
    "\n",
    "        # get an initial W and response\n",
    "        # assumes all weights have the same shape\n",
    "        W = weights[0]\n",
    "        res[0] = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "        # special case for conv2Dsvd \n",
    "        # assumes weights = [conv2D tensor] 1 matrix only\n",
    "        if conv2Dsvd:  # assume W is 4-index tensor\n",
    "            if len(weights)!=1:\n",
    "                msg = \"Only specific conv2Dsvd for 1 tensor: {}\".format(len(weights))\n",
    "                self.warn(msg)\n",
    "                res[0][\"message\"] = msg\n",
    "                return res\n",
    "            if len(W.shape)!=4:\n",
    "                msg = \"Conv2D kernel wrong size: {} {}\".format(W.shape, len(W.shape))\n",
    "                self.warn(msg)\n",
    "                res[0][\"message\"] = msg\n",
    "                return res\n",
    "        else:\n",
    "            if len(W.shape)!=2:\n",
    "                msg = \"Weight matrix wrong size: {}\".format(W.shape)\n",
    "                self.warn(msg)\n",
    "                res[0][\"message\"] = msg\n",
    "                return res\n",
    "\n",
    "        # handle special case now, save for loop later\n",
    "        if conv2Dsvd:\n",
    "            # is pytorch or tensor style \n",
    "            s = W.shape\n",
    "            self.debug(\"    Conv2D SVD ({}): Analyzing ...\".format(s))\n",
    "\n",
    "            N, M, imax, jmax = s[0],s[1],s[2],s[3]\n",
    "            # probably better just to check what col N is in \n",
    "            shape_type = \"pytorch\"\n",
    "            if N + M >= imax + jmax:\n",
    "                self.debug(\"Pytorch tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))    \n",
    "                fft_axes = [2,3]\n",
    "            else:\n",
    "                N, M, imax, jmax = imax, jmax, N, M          \n",
    "                shape_type = \"keras\"\n",
    "                fft_axes = [0,1]\n",
    "                self.debug(\"Keras tensor shape detected: {}x{} (NxM), {}x{} (i,j)\".format(N, M, imax, jmax))\n",
    "\n",
    "            #  receptive_field / kernel size\n",
    "            rf = np.min([imax, jmax])\n",
    "            # aspect ratio\n",
    "            Q = N/M \n",
    "            # num non-zero eigenvalues\n",
    "            n_comp = rf*N*M\n",
    "\n",
    "            # run FFT on each channel\n",
    "            fft_grid = [32,32]\n",
    "            fft_coefs = np.fft.fft2(W, fft_grid, axes=fft_axes)\n",
    "            # bug in svd, can not compute complex values\n",
    "            #svd = TruncatedSVD(n_components=n_comp, n_iter=7, random_state=10)\n",
    "            #svd.fit(fft_coefs)\n",
    "            #sv = svd.singular_values_\n",
    "            sv = np.linalg.svd(fft_coefs, compute_uv=False).flatten()\n",
    "            sv = np.sort(sv)[-n_comp:]\n",
    "            evals = sv*sv\n",
    "            frobenius_norm = np.sqrt(np.sum(evals))\n",
    "\n",
    "        elif stack_slices:\n",
    "            # this should be part of get_conv2Dmats\n",
    "            # replace weights with W\n",
    "            self.debug(\"stack slices N/A yet\")        \n",
    "            evals = None\n",
    "        elif merge_slices:\n",
    "            # compute all evals, merge\n",
    "            # really only for conv2D\n",
    "            # replace weights with W\n",
    "            self.debug(\"merge slices N/A yet\")\n",
    "            evals = None\n",
    "        else:\n",
    "            s = W.shape\n",
    "            N, M = np.max(s), np.min(s)\n",
    "            # aspect ratio\n",
    "            Q = N/M \n",
    "            evals = None\n",
    "\n",
    "            if M < min_size:\n",
    "                summary = \"Weight matrices too small {}  Skipping: (<{})\".format(W.shape, min_size)\n",
    "                res[0][\"summary\"] = summary \n",
    "                self.info(\"    {}\".format(summary))\n",
    "                return res\n",
    "\n",
    "            if max_size > 0 and M > max_size:\n",
    "                summary = \"Weight matrices too large {}  Skipping:  (>{})\".format(W.shape, max_size)\n",
    "                res[0][\"summary\"] = summary \n",
    "                self.info(\"    {}\".format(summary))\n",
    "                return res\n",
    "\n",
    "        # loop over all slices\n",
    "        for i, W in enumerate(weights):\n",
    "            res[i] = {}\n",
    "            res[i][\"N\"] = N\n",
    "            res[i][\"M\"] = M\n",
    "            res[i][\"Q\"] = Q\n",
    "\n",
    "            summary = []\n",
    "            self.debug(\"    Weight matrix {} {}/{} ({},{}): Analyzing ...\".format(layer_id, i+1, count, M, N))\n",
    "\n",
    "            if alphas:\n",
    "                if evals is None: \n",
    "                    sv = np.linalg.svd(W,  compute_uv=False())\n",
    "                    evals = sv*sv/N\n",
    "                    frobenius_norm = np.linalg.norm(W)\n",
    "\n",
    "                lambda_min, lambda_max = np.min(evals), np.max(evals)\n",
    "                fit = powerlaw.Fit(evals, xmax=lambda_max, verbose=False)\n",
    "                alpha = fit.alpha \n",
    "                D = fit.D\n",
    "\n",
    "                alpha_weighted = alpha * np.log10(lambda_max)\n",
    "                log_pnorm = np.log10(np.sum([ev**alpha for ev in evals]))\n",
    "\n",
    "                res[i][\"alpha\"] = alpha\n",
    "                res[i][\"D\"] = D\n",
    "                res[i][\"alpha_weighted\"] = alpha_weighted\n",
    "\n",
    "\n",
    "            if spectralnorms:  # always set if alphas set\n",
    "                if evals is None:\n",
    "                    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=10)\n",
    "                    svd.fit(fft_coefs)\n",
    "                    evals = sv*sv/N\n",
    "                    frobenius_norm = np.linalg.norm(W)    \n",
    "                    # check evals / norm\n",
    "\n",
    "                lambda_min, lambda_max = np.min(evals), np.max(evals)\n",
    "                spectral_norm = np.max(evals)\n",
    "\n",
    "                res[i][\"lambda_max\"] = lambda_max\n",
    "                res[i][\"lambda_min\"] = lambda_min\n",
    "                res[i][\"spectral_norm\"] = spectral_norm\n",
    "                res[i][\"spectral_normlog\"] = np.log10(spectral_norm)\n",
    "\n",
    "\n",
    "                # soft rank =  stable rank\n",
    "                softrank = (frobenius_norm**2) / spectral_norm\n",
    "                softranklog = np.log10(softrank)\n",
    "                softranklogratio = 2*np.log10(frobenius_norm) / np.log10(spectral_norm)\n",
    "\n",
    "                res[i][\"softrank\"] = softrank\n",
    "                res[i][\"softranklog\"] = softranklog\n",
    "                res[i][\"softranklogratio\"] = softranklogratio\n",
    "\n",
    "\n",
    "            # computations for all W\n",
    "            res[i][\"norm\"] = frobenius_norm\n",
    "            res[i][\"lognorm\"] = np.log10(frobenius_norm)\n",
    "\n",
    "            tolerance = lambda_max * M * np.finfo(np.max(sv)).eps\n",
    "            res[i][\"rank_loss\"] = np.count_nonzero(sv > tolerance, axis=-1)\n",
    "\n",
    "\n",
    "            if plot:\n",
    "                a = \"{:2f}\".format(alpha)\n",
    "                plt.hist(np.log10(evals),bins=100, label=a);\n",
    "                plt.title(\"AlexNet Layer {} W Log10 Eigenvales \\n Conv2D-SVD FFT approach\".format(layer_id))\n",
    "               \n",
    "                plt.xlabel(r\"$\\rho(\\log_{10}\\lambda)$\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "            #        if mp_fit:\n",
    "            #            do_mp_fit(N,M,Q,evals,sv)\n",
    "\n",
    "            # reset computations\n",
    "            evals = None\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-02 15:27:03,965 INFO \n",
      "\n",
      "python      version 3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.16.4\n",
      "tensforflow version 1.13.1\n",
      "keras       version 2.2.4\n"
     ]
    }
   ],
   "source": [
    "ww = WW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleshmartin/anaconda3/lib/python3.7/site-packages/powerlaw.py:1178: RuntimeWarning: overflow encountered in double_scalars\n",
      "  return (self.alpha-1) * self.xmin**(self.alpha-1)\n",
      "/Users/charleshmartin/anaconda3/lib/python3.7/site-packages/powerlaw.py:825: RuntimeWarning: invalid value encountered in multiply\n",
      "  likelihoods = f*C\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEpCAYAAACKmHkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5xVdb3/8dcbRPFWIuINROB4OZKJ1qSoWaZ2vOQRMyvTjFRC0VLLMrsco6tmncxTnhLFJG9FmkJaXg6JppUKiKU/U9LQJlEQIbykiH5+f3y/A5vN3jN7ZvaemTXzfj4e+zF7fdfaa33WnpnP/u7vWuuzFBGYmVnx9OvuAMzMrGOcwM3MCsoJ3MysoJzAzcwKygnczKygnMDNzArKCbwLSbpC0je6Ow7r/SQNl/SipP7dHUs1kiZLuqq74ygyJ/AGkDRb0jJJGzRw/a9I2q6k7SBJC2t8fZv/OJIWSjqok6HWlaT3Sbpb0nJJz0i6VNKmVZb9gqRfl7UtqNJ2TIXXj5AUktar8z68R9Idkv5Z6feVt3uHpJcl/aW130HuEKzMibrl8SBARDwVEZtExOv1jN96FifwOpM0AtgPCOCIBm7qJeC/Grj+blUlcb4Z+AawLbALMAz4TpVV3AXs29IDlbQ1MAB4W1nbDnnZrvIScDnwuSrzrwUeAAYDXwKukzSklfVdkBN1y2NMfcO1nswJvP4+BvwRuAIY39qCkg6XND/3KH8vabfc/m+Snpf0tjy9raTnJO1f8vL/AT4iaYcq695W0vWSlkj6m6TTc/shwBeBD5f22GolaZCkm/J6l+Xnw/K8D0qaW7b8WZJuzM83kPRdSU9JelbSjyVtmOftL6lZ0uclPQP8pHzbEXFNRNwSES9HxDLgUmDfKqHeT0rYu+fpdwF3AI+WtT0eEU+38z3YQNL3JT2dH98v/bYl6WxJi/K8Cbknv0Peh/si4krgiQrr3Ql4G/CViPhXRFwP/Bn4QHviy+ta6xuEpJGS7pL0gqT/k3Rx6bcwSWPz3+BySQ+W/q3lb3xfl3RPfv1tkrbI826R9MmybT8o6aj8/CJJf5e0QtJcSfu1EnNrMXxc0hN5+3+TdFx735PeyAm8/j4GXJ0fB0vaqtJCOTlfDpxM6m1dAsyUtEFEPA58Hrha0kakZHZFRMwuWcU/SAlscoV19wN+BTwIDAUOBM6UdHBE3AJ8C/h5B3ts/XI82wPDgX8BP8zzZgIjJe1SsvxHgSvz828DO5ES6A45tnNLlt0a2Dyve2INsbwLeLjSjIhYCdybl2lZ9nfA3WVtHel9fwkYS9qPMcCewJdh9QfkZ4CDSPv47nas9y3AExHxQknbg7m9s64B7iP9rU0Gjm+ZIWkocDPp283mwGeB68t6/scCJwBbAuvnZVrW+5GSdY0m/f5uzk33k96nzfOyv5A0sDy41mKQtDGpw3JoRGwK7APM7+D70LtEhB91egDvBF4DtsjTfwE+XTL/CuAb+fmPgK+Xvf5R4N0l0zNJPbA/ARuUtM8GJgBDgH+S/sEPAhbm+XsBT5Wt+wvAT/LzycBVbezLQuCgGvZ5d2BZyfSPgG/m528BlgEbACINH/xbybJ7A3/Lz/cHVgIDa3yv35vXvVMry0wGbsjPHwR2BA4paxtf5bUjSMNg61WY9zhwWMn0wSXv/eXAeSXzdsjr2aFsHat/XyVtxwN/LGv7JunDu1KMVwCvAMtLHtPK4yd90K4CNip57VUtfwOkzsKVZeu+teW9yX9vXy6ZdypwS36+af69bl8S7+Wt/E6WAWPK/w5biwHYOO/bB4AN6/G/2lse7oHX13jgtoh4Lk9fQ/VhlO2Bs/LXxeWSlgPbkcZ3W1wK7Ar8ICJeLV9BRCwh9X6/VmHd25at+4tAxW8D7SFpI0mXSHpS0gpSD3YzrTnbYRpwrCSREtL0HPsQYCNgbklMt+T2Fksi4pUaYhhLem+PjojHWln0LuCdkgYBQyJiAfB7YJ/ctisd64FvCzxZMv0ka35v2wJ/L5lX+rwtLwJvKmt7E/BChWVbfDciNit5VPp72xZ4PiJerhLX9sAHy/5e3glsU7LMMyXPXwY2AYj0beFmoOVA8DGkb5/A6iG0R5QO2i4nHcfYokKMVWOIiJeADwOnAIsk3Szp31t5T/qMuh5h78vyWO6HgP55DBdSz3MzSWMionys+e+knuo3q6xvE+D7wFRgsqTrI+L5Cot+hzSeel/Zuv8WETtWCbczJSjPAnYG9oqIZyTtTjroJoCI+KOklaQDucfmB8BzpOGWt0TEPzoal6Q9SN9MToyIWW0s/gdSwpgI3JPjWyHp6dz2dET8ra1tVvA0KeG0DN8Mz20Ai0gHV1tsR+0eBkZJ2jTWDKOMIX1YdcYiYHNJG5Uk8dK4/k7q/X6ig+u/FviKpLuADUnHGsjj3Z8nDeE9HBFvSFpG/lsp02oMEXErcGv+P/sGqXNTdTy9r3APvH6OBF4HRpOGFXYnnSnxO9K4eLlLgVMk7aVkY6XT5FpOi7sImBsRE0g9nB9X2mhELAf+Gzi7pPk+YEU+ILihpP6SdpX0jjz/WWBEHitvzQBJA0se65G+Mv8LWC5pc+ArFV73U9I3g1URcXeO8428zxdK2hLSuKekg9uIYTVJu5J67Z+KiF+1tXxE/AuYQxqT/l3JrLtzWy297w3K3oN+pIT15Tw+uwVpHL/lgOB04ARJu+TjF6Vj/Ejql8eAB6RJDZS0fo73MdLY7ldy+/uB3YDra4izqoh4kvQ+TJa0vqS9gf8sWeQq4D8lHZz/VgYqHVQeVnGF6/o16QPta6RjK2/k9k1JQzdLgPUkncu63zDajEHSVpKOyGPhr5K+qfj0SPAYeL0epMTy3xXaP0T6+rkeJWPged4hpIM8y0m9pF+Q/ujHkQ5Sbp6X2wT4K3Bcnp4NTChZzybAYkrGVElfm6/N215GOjPmoDxvMCmJLQPmVdmfhaQecemj5RS+2aR/osdIB2HXGism9UjfAL5ats6BpAOoTwArgEeA0/O8/YHmNt7jn+T1vljyeLiN15yX43tb2e8kgJNbed2ICvsfpLHrgaSDaovy438oGbsnHW94htQrn5Rft13Jfpavc3bZdmeTPiQfpZXjEPnvaWXZ+/FcWfzr5el/I32IvQDMAqYAU0vWtRdwJ/A8KeHeDAyv8vf2ceDuslim5u29o6Stf25fkd+nsyk5tkLZsZhqMZCGcu4kHe9ZnuMZ3d3/8z3hofzGmdVN/pq7mJQ0F3R3PN0pn5HzEOkg9KrujqeFpJ8Df4mISt+grCA8hGKNMAm4v68mb0nvz0MVg0inTv6qu5O3pHcoXV/QL5/qOA64sTtjss7zQUyrK6XLw0U6JtBXnUwa3nid9NX/1G6NJtka+CVp+KwZmBQRD3RvSNZZHkIxMysoD6GYmRWUE7iZtZtSfZQJ3R1HX+cE3svkc8pPl/SQpJeUCkT9QtJbG7zdz+VtthQb+lzZ/MjxvChpqaRZkj7cxjrXl/TfeR9ezOu9MM+7VVL5FahIGqdUanY9rSm3+kJ+PCTpPElvbmWbkyW9prVLtJ6d57WU8S2d9+6y6dL9fFGtFG8y6ywn8N7nIuAM4HRSUaCdSGcbvK/B2xXpgqVBpPPbP6l162yPiYhNSFdyXgH8UFJrp7F9AWgiFYvaFHgP6apP8uuPl1R+Vd/xwNUlZ31cEKkA0hBSMaaxwD35opBqWgp9tTwuKJn3ybJ5d5ZOl+5nfvyu0ga6gupcy9x6HifwXkTSjsBpwEci4rcR8Wqk0qtXR8T5eZk3S/qpUjnYJyV9ueWKTKWSnXcrlXxdlnu8h+Z5x0iaU7a9T0uaCRARF0TEvIhYFRGPAjOoUuo1Ip6LVFJ1EvAFSYOr7NI7SIWnno5kYUT8NM+7kfQBtbqHm0/bO5x0JWj5Nl+JiPtJNdoHk5J5t5B0glJ9kBeUSqSeXDKvpazuF5VKCC9USenU/K3ix5Juz6+/U9L2JfND0mmSFgALcts+ku5Xqkdyv6R9aoklzx+nVPJ4haTH8ymILbZXhRKz1nWcwHuXA0lXM97XyjI/INUHGUUqdfox1k5me5GuANwCuACYmnu5M4Gd84dEi2OpUKcjL78fVUq9lphBOpV1zyrz/wh8RtKpkt5a2tuOdJn8dNYuU/Ah0sUpVWucR6oxcjvdW0djMemD5k2k9/5C5drv2dak938oqRjaFEk7l8w/Dvh6XmY+JcWjsiNJv8fRSuUObiZdLToY+B5wc8mHZtVYJO1J+jD8HLAZqfzuwpLtVCsxa12luy8F9aN+D1Kd6j+2Mr8/qZbE6JK2k8mXcpMukf5rybyNSJdHb52nrwLOzc93JF2WvVGF7XyVVKq1tATuOiVVc/sz5BIBVeI9jVSI6lXSpenjS+a/k3R59YZ5+h6qlO8tW+/5wO1VtjmZdHl6aYnWbfO82aRKfC3t65QhqLafbfzebgTOyM/3J9UP2bhk/nTgv0r26Wcl8zYhnW++Xcn2DyiZfzxwX9n2/gB8vIZYLgEurLLcbKqUmPWj6x7ugfcuS1m7BGi5LUg9pfJSqENLpleXDY01letaxnZLi/cfC9wYa5coRenuLB8D3hcVSuCWLTuANDb9vKT9Sg78PZy3/3pEXBwR+5J6gN8ELle+YUSkQllLgHGSRpGGXGqp3DeUVG+jmumxdonW0jv2nF7S/raqa2iFpEMl/VHprkvLgcNYu8TqskglVFuUlquFklKwEfFi3peK81m39G3L+obWEMt2pNrn1VQsMWtdxwm8d5kFDJPUVGX+c6QbTmxf0jacVDirFrcBWyiVkP0IZclS0onAOcCBEdFcw/rGkXqb90XE72LNgb917kAT6RZjF5MKcI0umfVT0gfG8aRa7M+2tkGlMr0HsXZ1wi6jdOu164HvAltFxGakan6lB2MHlR1kLS1XCyWlYPP+bF42v/TqvJbSt6WGA/+oIZa/k4pgWQ/lBN6LRKo98r/Atflg2PpKZTmPkXROpDuUTwe+KWnTfPDrM6wphdrW+lcB15FqkG9OGksGIB9o+xbw3ohY536PpSRtnpe/GPh2RCytstyZeT82VDotcDzpbJTSS8B/SkrInyDdTKLaNjeQ9HbSEMEyKtxzs4usT6oTvwRYlQ8S/0eF5b6af3/7kcaof1Ey7zBJ71QqQ/t14N6IqHbjiF8DO0k6Nr+HHyZ9AN5UQyxTSaVxD1SqoTJUvpFCj+IE3vucTqrFfTFpnPZx4P2ke2QCfIp0C6wnSCVlryHdBqxW15AS5i9i7QJN3yAdJLu/ZCikvIb5g5JeJJXGnUAarz6X6v5FqnX+DOnbw2nAB0o/ICJiIekuOxuTDrSWO1vSC6Rhhp8Cc4F9yoYoukykg6inkz5Il5GGosrjbikB/DTpAOUpEfGXkvnXkOqwPw+8nXRQs9r2lpI+AM4iDbGdDRwe6UygVmOJdDD8BOBC0rGGO1m3N2/dyLVQzHoQpTuxXxURFW+mIOkK0plGX+7KuKxncg/czKygnMDNzArKQyhmZgXlHriZWUF1abGbLbbYIkaMGNGVmzQzK7y5c+c+FxFDytu7NIGPGDGCOXPmtL2gmZmtJqn8alrAQyhmZoXlBG5mVlBO4GZmBeU7dphZp7z22ms0NzfzyiuvdHcohTdw4ECGDRvGgAEDalreCdzMOqW5uZlNN92UESNGoHXucGe1igiWLl1Kc3MzI0eOrOk1HkIxs0555ZVXGDx4sJN3J0li8ODB7fom02YCl7Rzvidey2NFLvO5eb4v34L8c1CnojezwnLyro/2vo9tJvCIeDQido+I3UmlK18GbiAV7p8VETuSbiRwTvvDNTOzjmrvGPiBwOMR8aSkcaT790EqpD8b+Hz9QjOzIhpxzs11Xd/C899X03Kvv/46TU1NDB06lJtuummd+dOnT2fy5MlIYsyYMVxzTbqhVP/+/XnrW98KwPDhw5k5M5VEP+6445gzZw4DBgxgzz335JJLLmHAgAFcffXVfPvb3wZgk0024Uc/+hFjxowBYPny5UyYMIGHHnoISVx++eXsvffeTJ48mUsvvZQhQ9LFlN/61rc47LDDOvfG0P4EfgxwbX6+VUQsAoiIRZK2rPQCSROBiZDeHDOrn9JkWWui660uuugidtllF1asWLHOvAULFnDeeedxzz33MGjQIBYvXrx63oYbbsj8+fPXec1xxx3HVVelm1Ude+yxXHbZZUyaNImRI0dy5513MmjQIH7zm98wceJE7r33XgDOOOMMDjnkEK677jpWrlzJyy+vuWXspz/9aT772c/WdZ9rPoiZb990BGvf2qlNETElIpoioqnl08fMrJ6am5u5+eabmTBhQsX5l156KaeddhqDBqVDdVtuWbG/uZbDDjsMSUhizz33pLk53eZ1n332Wb2esWPHrm5fsWIFd911FyeddBIA66+/Pptttlmn96017TkL5VBgXslNY5+VtA1A/rm46ivNzBrozDPP5IILLqBfv8op7bHHHuOxxx5j3333ZezYsdxyyy2r573yyis0NTUxduxYbrzxxnVe+9prr3HllVdyyCGHrDNv6tSpHHrooQA88cQTDBkyhBNOOIE99tiDCRMm8NJLa+7c98Mf/pDddtuNE088kWXLlnV2l4H2JfCPsGb4BNK988bn5+OBGXWJyMzWMeKcm1c/bG033XQTW265JW9/+9urLrNq1SoWLFjA7Nmzufbaa5kwYQLLly8H4KmnnmLOnDlcc801nHnmmTz++ONrvfbUU0/lXe96F/vtt99a7XfccQdTp05dPR6+atUq5s2bx6RJk3jggQfYeOONOf/88wGYNGkSjz/+OPPnz2ebbbbhrLPOqsu+15TAJW0EvBf4ZUnz+cB7JS3I886vS0RmZu1wzz33MHPmTEaMGMExxxzDb3/7Wz760Y+utcywYcMYN24cAwYMYOTIkey8884sWLAAgG233RaAUaNGsf/++/PAAw+sft1Xv/pVlixZwve+97211venP/2JCRMmMGPGDAYPHrx6G8OGDWOvvfYC4Oijj2bevHkAbLXVVvTv359+/frxiU98gvvuu68u+15TAo+IlyNicET8s6RtaUQcGBE75p/P1yUiM7N2OO+882hubmbhwoX87Gc/44ADDlh98LHFkUceyR133AHAc889x2OPPcaoUaNYtmwZr7766ur2e+65h9GjRwNw2WWXceutt3LttdeuNTTz1FNPcdRRR3HllVey0047rW7feuut2W677Xj00UcBmDVr1up1LVq0aPVyN9xwA7vuumtd9t2X0ptZXfWUs2HOPfdcmpqaOOKIIzj44IO57bbbGD16NP379+c73/kOgwcP5ve//z0nn3wy/fr144033uCcc85ZnXRPOeUUtt9+e/bee28AjjrqKM4991y+9rWvsXTpUk499VQA1ltvvdX3OfjBD37Acccdx8qVKxk1ahQ/+clPADj77LOZP38+khgxYgSXXHJJXfaxS++J2dTUFL6hg1n7VTtdsCecRvjII4+wyy67dMu2e6NK76ekuRHRVL6sa6GYmRWUE7iZWUE5gZtZp3XlUGxv1t730QnczDpl4MCBLF261Em8k1rqgQ8cOLDm1/gsFLNeorsOaA4bNozm5maWLFnSZdvsrVruyFMrJ3Az65SWi2Os63kIxcysoJzAzcwKygnczKygPAZu1s3ae/DRFQmthXvgZmYF5QRuZlZQTuBmZgXlBG5mVlBO4GZmBeWzUMy6SFeebdIT6oRb47kHbmZWUE7gZmYFVdMQiqTNgMuAXYEATgQeBX4OjAAWAh+KiGUNidLMOszDKb1XrT3wi4BbIuLfgTHAI8A5wKyI2BGYlafNzKyLtJnAJb0JeBcwFSAiVkbEcmAcMC0vNg04slFBmpnZutq8K72k3YEpwP8j9b7nAmcA/4iIzUqWWxYRgyq8fiIwEWD48OFvf/LJJ+sXvVmB9LQaJh5OKY7O3JV+PeBtwI8iYg/gJdoxXBIRUyKiKSKahgwZUnPAZmbWuloSeDPQHBH35unrSAn9WUnbAOSfixsTopmZVdJmAo+IZ4C/S9o5Nx1IGk6ZCYzPbeOBGQ2J0MzMKqr1SsxPAVdLWh94AjiBlPynSzoJeAr4YGNCNDOzSmpK4BExH1hnAJ3UGzczs27gKzHNzArKCdzMrKCcwM3MCsoJ3MysoJzAzcwKygnczKygnMDNzArKCdzMrKCcwM3MCsoJ3MysoJzAzcwKygnczKygnMDNzArKCdzMrKCcwM3MCqrWGzqYWQf0tBsZlyqNzTc4Lib3wM3MCsoJ3MysoJzAzcwKygnczKygnMDNzAqqprNQJC0EXgBeB1ZFRJOkzYGfAyOAhcCHImJZY8I0s57EZ7D0DO3pgb8nInaPiKY8fQ4wKyJ2BGblaTMz6yKdGUIZB0zLz6cBR3Y+HDMzq1WtCTyA2yTNlTQxt20VEYsA8s8tK71Q0kRJcyTNWbJkSecjNjMzoPYrMfeNiKclbQncLukvtW4gIqYAUwCampqiAzGamVkFNfXAI+Lp/HMxcAOwJ/CspG0A8s/FjQrSzMzW1WYCl7SxpE1bngP/ATwEzATG58XGAzMaFaSZma2rliGUrYAbJLUsf01E3CLpfmC6pJOAp4APNi5MMzMr12YCj4gngDEV2pcCBzYiKDMza5vLyZrVUU8uH1srX6RTHL6U3sysoJzAzcwKygnczKygnMDNzArKCdzMrKCcwM3MCsoJ3MysoJzAzcwKyhfymFmn+MKf7uMeuJlZQTmBm5kVlIdQzKxX1HDpi9wDNzMrKCdwM7OCcgI3MysoJ3Azs4JyAjczKyifhWLWAX3l4pW+sp9F5R64mVlB1ZzAJfWX9ICkm/L0SEn3Slog6eeS1m9cmGZmVq49PfAzgEdKpr8NXBgROwLLgJPqGZiZmbWupgQuaRjwPuCyPC3gAOC6vMg04MhGBGhmZpXV2gP/PnA28EaeHgwsj4hVeboZGFrphZImSpojac6SJUs6FayZma3RZgKXdDiwOCLmljZXWDQqvT4ipkREU0Q0DRkypINhmplZuVpOI9wXOELSYcBA4E2kHvlmktbLvfBhwNONC9PMzMq12QOPiC9ExLCIGAEcA/w2Io4D7gCOzouNB2Y0LEozM1tHZ84D/zzwGUl/JY2JT61PSGZmVot2XYkZEbOB2fn5E8Ce9Q/JzMxq4Uvpzcr48vHKfNOHnseX0puZFZQTuJlZQTmBm5kVlBO4mVlBOYGbmRWUz0Ix6ySfnWHdxT1wM7OCcgI3MysoJ3Azs4JyAjczKygncDOzgnICNzMrKCdwM7OCcgI3MysoX8hj1gqXlm08v8cd5x64mVlBOYGbmRWUh1DMrMtVqx/j4ZT2cQ/czKygnMDNzAqqzSEUSQOBu4AN8vLXRcRXJI0EfgZsDswDjo+IlY0M1qw7uWys9TS19MBfBQ6IiDHA7sAhksYC3wYujIgdgWXASY0L08zMyrWZwCN5MU8OyI8ADgCuy+3TgCMbEqGZmVVU01kokvoDc4EdgIuBx4HlEbEqL9IMDK3y2onARIDhw4d3Nl4z68F8FknXqukgZkS8HhG7A8OAPYFdKi1W5bVTIqIpIpqGDBnS8UjNzGwt7ToLJSKWA7OBscBmklp68MOAp+sbmpmZtaaWs1CGAK9FxHJJGwIHkQ5g3gEcTToTZTwwo5GBmlmxeDil8WoZA98GmJbHwfsB0yPiJkn/D/iZpG8ADwBTGxinmZmVaTOBR8SfgD0qtD9BGg83M7Nu4CsxzcwKygnczKygnMDNzArK5WTNzEoU6ewZ98DNzArKCdzMrKA8hGJmPV6RhjW6knvgZmYF5QRuZlZQHkIxs8Lq60Mr7oGbmRWUE7iZWUF5CMXMeqRG3ES62pBLUW9Y7R64mVlBOYGbmRWUE7iZWUE5gZuZFZQTuJlZQfksFDOKexaCta03/27dAzczK6g2E7ik7STdIekRSQ9LOiO3by7pdkkL8s9BjQ/XzMxa1DKEsgo4KyLmSdoUmCvpduDjwKyIOF/SOcA5wOcbF6r1ZX295oVZJW32wCNiUUTMy89fAB4BhgLjgGl5sWnAkY0K0szM1tWuMXBJI4A9gHuBrSJiEaQkD2xZ7+DMzKy6ms9CkbQJcD1wZkSskFTr6yYCEwGGDx/ekRjN1lKv4ZTefHZCT+P3ujFq6oFLGkBK3ldHxC9z87OStsnztwEWV3ptREyJiKaIaBoyZEg9YjYzM2o7C0XAVOCRiPheyayZwPj8fDwwo/7hmZlZNbUMoewLHA/8WdL83PZF4HxguqSTgKeADzYmRLP281krfU8jfue1lJ/tzr+vNhN4RNwNVBvwPrC+4ZiZWa18JaaZWUG5FoqZFUotZ7T0lbNe3AM3MysoJ3Azs4LyEIr1ej3ljAGzenMP3MysoNwDN7M+qb0HOnvigVH3wM3MCsoJ3MysoDyEYj1WT/zKataTuAduZlZQTuBmZgXlIRQrNJ/jbX2Ze+BmZgXlBG5mVlAeQrE+xWe2WG/iHriZWUE5gZuZFZQTuJlZQTmBm5kVlBO4mVlBtXkWiqTLgcOBxRGxa27bHPg5MAJYCHwoIpY1LkzracrP5vBFNNZXdefFZLX0wK8ADilrOweYFRE7ArPytJmZdaE2E3hE3AU8X9Y8DpiWn08DjqxzXGZm1oaOjoFvFRGLAPLPLastKGmipDmS5ixZsqSDmzMzs3INP4gZEVMioikimoYMGdLozZmZ9RkdTeDPStoGIP9cXL+QzMysFh1N4DOB8fn5eGBGfcIxM7NatZnAJV0L/AHYWVKzpJOA84H3SloAvDdPm5lZF2rzPPCI+EiVWQfWORYzM2sHl5O1mnVFKVaXezWrnS+lNzMrKCdwM7OC8hCKdYtGDJV4+MX6GvfAzcwKygnczKygnMDNzArKCdzMrKCcwM3MCspnoViX8Vki1tt19d153AM3MysoJ3Azs4LyEIoBnf/qV214xDc7tr6qK4ZT3AM3MysoJ3Azs4LyEEoP1t6vYNWWr6W9M9s1s+7hHriZWUE5gZuZFZSHUPqY9l5M09mLb3zxjlnjuAduZlZQTuBmZgXVqSEUSYcAFwH9gU196esAAAY9SURBVMsi4vy6RFVBd10o0toQQHu3Xa/hhFrOEvHQhVnv1+EeuKT+wMXAocBo4COSRtcrMDMza11nhlD2BP4aEU9ExErgZ8C4+oRlZmZtUUR07IXS0cAhETEhTx8P7BURnyxbbiIwMU/uDDza8XAbZgvgue4Oogv0hf3sC/sIfWM/+8I+Qm37uX1EDClv7MwYuCq0rfNpEBFTgCmd2E7DSZoTEU3dHUej9YX97Av7CH1jP/vCPkLn9rMzQyjNwHYl08OApzuxPjMza4fOJPD7gR0ljZS0PnAMMLM+YZmZWVs6PIQSEaskfRK4lXQa4eUR8XDdIutaPXqIp476wn72hX2EvrGffWEfoRP72eGDmGZm1r18JaaZWUE5gZuZFZQTeAlJn5L0qKSHJV3Q3fE0iqTPSgpJW3R3LI0g6TuS/iLpT5JukLRZd8dUL5IOyX+jf5V0TnfH0wiStpN0h6RH8v/iGd0dU6NI6i/pAUk3deT1TuCZpPeQriTdLSLeAny3m0NqCEnbAe8FnuruWBrodmDXiNgNeAz4QjfHUxd9qHzFKuCsiNgFGAuc1kv3E+AM4JGOvtgJfI1JwPkR8SpARCzu5nga5ULgbCpcdNVbRMRtEbEqT/6RdI1Cb9AnyldExKKImJefv0BKcEO7N6r6kzQMeB9wWUfX4QS+xk7AfpLulXSnpHd0d0D1JukI4B8R8WB3x9KFTgR+091B1MlQ4O8l0830wsRWStIIYA/g3u6NpCG+T+pMvdHRFfSpO/JI+j9g6wqzvkR6LwaRvrK9A5guaVQU7DzLNvbxi8B/dG1EjdHafkbEjLzMl0hfx6/uytgaqKbyFb2FpE2A64EzI2JFd8dTT5IOBxZHxFxJ+3d0PX0qgUfEQdXmSZoE/DIn7PskvUEqMrOkq+Krh2r7KOmtwEjgQUmQhhXmSdozIp7pwhDrorXfJYCk8cDhwIFF+xBuRZ8pXyFpACl5Xx0Rv+zueBpgX+AISYcBA4E3SboqIj7anpX4Qp5M0inAthFxrqSdgFnA8F70z78WSQuBpojoddXe8o1Gvge8OyIK9QHcGknrkQ7KHgj8g1TO4tgCXwFdkVIPYxrwfESc2d3xNFrugX82Ig5v72s9Br7G5cAoSQ+RDg6N763Juw/4IbApcLuk+ZJ+3N0B1UM+MNtSvuIRYHpvS97ZvsDxwAH59zc/91StjHvgZmYF5R64mVlBOYGbmRWUE7iZWUE5gZuZFZQTuJlZQTmBm5kVlBO4mVlBOYFbryFpw1yIrH+efrHB23urpCdzGYaWtvUl3ZWvmjRrKCdw601OJNWzeb0rNhYRfwaOAT5W0raSVIbhw10Rg/VtTuBWSJJOlfRQ7gF/KjcfB8yosvxn8vIPSTqzpP2/8t17bpd0raTPtjOUxcBbytpuzLGYNZS/5lnhSPoA6a5Ce5AqRv5Z0iXAqIhYWGH5twMnAHuRSrLeK+lOoD/wgbye9YB5wNx2hnM+sIGk7SPiydz2EKkksVlDOYFbEZ0OfCIiXgMWSXqNVBt8eZXl3wncEBEvAUj6JbAf6RvojIj4V27/Vf45ilQ//c0RcXRu2xj4X2AlMDsirs5VDzcGbib1wp8EiIjXJa2UtGm+o4xZQ3gIxQol14neLSIey9PbAM8BL5DqKld8WXva8y3LTiprPgq4LiI+QarjPBC4ADgV+DOwa9nyGwCvtLE7Zp3iBG5FMxp4s6RRkvoB5wE/iIhlQP+cWMvdBRwpaaPck34/8DvgbuA/JQ3Md395XyvbHcaa25m9DnwZ+GkeslkrgUsaDCzJ3xDMGsYJ3IpmD9It0q4F/gQ8FRFT8rzbSMMla8k3yL0CuI90b8XLIuKBiLgfmAk8CPwSmAP8s8p2m1lzc+QNSWPw38/T5T3w9wC/7sC+mbWL64FboUj6PvCHiPh5hXl7AJ+JiOPbsb5NIuJFSRuReuoTSWPZ3yQl6csi4rzcc/8haVjk7oioep/NPMb+hYh4tD37ZtZePohpRbM78KNKMyLiAUl3SOrfjnPBp0gaTRo/n5Z76wCnlK37JdKZLK2StD5wo5O3dQX3wM3MCspj4GZmBeUEbmZWUE7gZmYF5QRuZlZQTuBmZgXlBG5mVlBO4GZmBfX/ATjI4TxY+e8qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "for im, m in enumerate(alexnet.modules()):\n",
    "    if  im > 1 and \"Conv2d\" in str(m):\n",
    "        print(im,m)\n",
    "        W = np.array(m.weight.data.clone().cpu()) \n",
    "        results = ww.analyze_weight_matrices([W], layer_id=im, conv2Dsvd=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
