{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbb00d6a-57bf-483f-9172-667a93a7a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4b014b-ed1f-44eb-8f83-a5569cbc7876",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (weightwatcher.py, line 2699)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\users\\feder\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3441\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-2-b51d2f5299b9>\"\u001b[0m, line \u001b[0;32m12\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import weightwatcher as ww\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\feder\\WeightWatcher\\weightwatcher\\__init__.py\"\u001b[1;36m, line \u001b[1;32m29\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from .weightwatcher import WeightWatcher\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\feder\\WeightWatcher\\weightwatcher\\weightwatcher.py\"\u001b[1;36m, line \u001b[1;32m2699\u001b[0m\n\u001b[1;33m    else\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import powerlaw\n",
    "import tensorflow_addons as tfa\n",
    "import copy\n",
    "import weightwatcher as ww\n",
    "import imageio\n",
    "from datetime import datetime\n",
    "import io\n",
    "import cv2\n",
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "import random\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"weightwatcher\")\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3c5c1-6e59-425b-9cf5-5bfb45562d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "inputShape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# shuffle training set and its labels accordingly\n",
    "trainingIndexes = np.arange(0,y_train.shape[0]).tolist()\n",
    "random.shuffle(trainingIndexes)\n",
    "x_train = x_train[trainingIndexes,:,:,:]\n",
    "y_train = y_train[trainingIndexes,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470b7bf-5cdf-479d-be1a-8afbb1df77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENET model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer(input_shape=inputShape),\n",
    "        layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "        layers.MaxPool2D(strides=2),\n",
    "        layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'),\n",
    "        layers.MaxPool2D(strides=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(84, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d76101-0625-4f54-8515-d2d4476c8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function which returns an image as numpy array from figure\n",
    "def get_img_from_fig(fig, dpi=180):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=dpi)\n",
    "    buf.seek(0)\n",
    "    img_arr = np.frombuffer(buf.getvalue(), dtype=np.uint8)\n",
    "    buf.close()\n",
    "    img = cv2.imdecode(img_arr, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b8567-69db-4fd5-a5b7-a5af208498ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingSize = 256\n",
    "testSize = 10000\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "learningRate = .001\n",
    "selectComponentsMethod = \"mp_spikes\" #\"percentage\" #\"classic\" #\"percentage\" #\"powerlaw_spikes\" #\"mp_spikes\" #\"powerlaw_xmin\"\n",
    "percentageKept = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dbf5a-634f-4209-b905-ce2337cebf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updatable plot\n",
    "# a minimal example (sort of)\n",
    " \n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.test_losses = []\n",
    "        self.estimatedLosses = []\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "        now = datetime.now()\n",
    "        date_time = now.strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "        self.writer = imageio.get_writer(\"training-\" + date_time + \".mp4\", format = \"FFMPEG\", mode='I', fps = 1)\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if selectComponentsMethod == \"powerlaw_xmin\" or selectComponentsMethod == \"powerlaw_spikes\":\n",
    "            self.fig, self.axes = plt.subplots(2,3,figsize=(25,10)) \n",
    "        elif selectComponentsMethod == \"mp_spikes\":\n",
    "            self.fig, self.axes = plt.subplots(1,4,figsize=(25,5)) \n",
    "        elif selectComponentsMethod == \"percentage\":\n",
    "            self.fig, self.axes = plt.subplots(figsize=(10,7))\n",
    "\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.test_losses.append(model.evaluate(x_test[0:testSize], y_test[0:testSize], verbose=0)[0])\n",
    "                \n",
    "        # careful! Python is dangerous :) as opposed to MATLAB, it can modify the contents of an object from inside a function even if that wasn't asked for.\n",
    "        # so before we begin, do a deep copy (keras clone) of the model and work with that\n",
    "        modelToSmooth = keras.models.clone_model(model)\n",
    "        modelToSmooth.build(model.input_shape) \n",
    "        modelToSmooth.compile(loss=model.loss, optimizer=model.optimizer, metrics=[\"accuracy\"])\n",
    "        modelToSmooth.set_weights(model.get_weights())\n",
    "\n",
    "        watcher = ww.WeightWatcher(model=modelToSmooth)\n",
    "\n",
    "        if selectComponentsMethod == \"powerlaw_xmin\" or selectComponentsMethod == \"powerlaw_spikes\":\n",
    "            resultFunction = watcher.unifiedSVDSmoothing(methodSelectComponents = selectComponentsMethod, doPlot = True, axes = [self.axes[0,1],self.axes[0,2],self.axes[1,0],self.axes[1,1]])\n",
    "        elif selectComponentsMethod == \"mp_spikes\":\n",
    "            resultFunction = watcher.unifiedSVDSmoothing(methodSelectComponents = selectComponentsMethod, doPlot = True, axes = [self.axes[1],self.axes[2],self.axes[3]])\n",
    "        elif selectComponentsMethod == \"percentage\":\n",
    "            resultFunction = watcher.unifiedSVDSmoothing(methodSelectComponents = selectComponentsMethod, percent = percentageKept / 100)\n",
    "\n",
    "        self.estimatedLosses.append(resultFunction[0].evaluate(x_train[0:100], y_train[0:100], verbose=0)[0])\n",
    "     \n",
    "        self.i += 1\n",
    "                        \n",
    "        if selectComponentsMethod == \"powerlaw_xmin\" or selectComponentsMethod == \"powerlaw_spikes\":\n",
    "            self.axes[0,0].plot(self.x, self.losses, label=\"loss\")\n",
    "            self.axes[0,0].plot(self.x, self.test_losses, label=\"test_loss\")\n",
    "            self.axes[0,0].plot(self.x, self.estimatedLosses, label=\"SVDestimate_\" + str(resultFunction[1]) + \"c\")\n",
    "            self.axes[0,0].title.set_text(\"Training sample: N\" + str(trainingSize) + \", test sample: N\" + str(testSize) + \", using \" + selectComponentsMethod) #, fontdict=None, loc='center')\n",
    "            self.axes[0,0].legend()\n",
    "        elif selectComponentsMethod == \"mp_spikes\":\n",
    "            self.axes[0].plot(self.x, self.losses, label=\"loss\")\n",
    "            self.axes[0].plot(self.x, self.test_losses, label=\"test_loss\")\n",
    "            self.axes[0].plot(self.x, self.estimatedLosses, label=\"SVDestimate_\" + str(resultFunction[1]) + \"c\")\n",
    "            self.axes[0].title.set_text(\"Training sample: N\" + str(trainingSize) + \", test sample: N\" + str(testSize) + \", using \" + selectComponentsMethod) #, fontdict=None, loc='center')\n",
    "            self.axes[0].legend()\n",
    "        elif selectComponentsMethod == \"percentage\":\n",
    "            self.axes.plot(self.x, self.losses, label=\"loss\")\n",
    "            self.axes.plot(self.x, self.test_losses, label=\"test_loss\")\n",
    "            self.axes.plot(self.x, self.estimatedLosses, label=\"SVDestimate_\" + str(resultFunction[1]) + \"c\")\n",
    "            self.axes.title.set_text(\"Training sample: N\" + str(trainingSize) + \", test sample: N\" + str(testSize) + \", using \" + selectComponentsMethod) #, fontdict=None, loc='center')\n",
    "            self.axes.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        data = get_img_from_fig(self.fig)\n",
    "        self.writer.append_data(data)\n",
    "\n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "      self.writer.close()\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e8c2b-8f03-40ad-b295-3b3aaffa296d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#opt = keras.optimizers.SGD(learning_rate=.01, momentum = 0.9) \n",
    "opt = keras.optimizers.Adam(learning_rate=learningRate)\n",
    " \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "model.fit(x_train[0:trainingSize], y_train[0:trainingSize], batch_size=batch_size, epochs=epochs, validation_split=0, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e14a4-9f26-49be-a045-b4e3bf058863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca12b12-d4ed-4762-9986-67f61ae6a076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64442dd3-b455-4fc7-a55c-f508b86eca74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc880f-19ca-4bd0-b701-be988e2326b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfa5cd-d2f7-4595-b402-e33aa9b510ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6da70e-02f3-4291-bc49-c031c73c7dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844cbf0-8479-4be3-b9bb-c6896293f169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da2c2a-991a-4d5a-aa45-f24d815ce1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
